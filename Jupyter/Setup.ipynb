{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASHviz: Getting Started\n",
    "\n",
    "Sometime in 2017 I had done some data visualization experiments on ASH dump data I had obtained quite awhile ago. The data was from a 4-node RAC database running Oracle 10.2 under nontrivial load. So it's raw and real data.\n",
    "\n",
    "I created a user group presentation using plots generated from the scripts but the process was painful and showing pure images without code context not all that instructive. I thought of just running the scripts in R Studio but that would have been extremely difficult to follow, albeit satisfying to see images generated in real time.\n",
    "\n",
    "I had heard about iPython Notebooks and these seemed perfect for combining ability to run code and put context and discussion around it in formatted text. At the time converting the R to Python seemed like more work than I wanted to do just to start so I didn't. Learning that Jupyter Notebooks (successor to iPython) had an R kernel in addition to Python was enough to resurrect the project, as there definitely were interesting findings worth sharing there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaconda\n",
    "\n",
    "One thing about programming in R and Python is the incredible amount of free and useful libraries and packages out there to use. There's tons of stuff and you want to be able to just use something you read about without going through a bunch of installation rigamarole first.\n",
    "\n",
    "The open-source [Anaconda Distribution](https://www.anaconda.com) is a complete package management platform that manages dependencies and keeps versions updated for literally hundreds of packages and tools spanning multiple languages. Anything you want in R or Python is likely to be in there. Anaconda includes R Studio and Jupyter Notebooks. Recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks\n",
    "\n",
    "Upon starting Jupyter Notebooks for the first time I couldn't believe how simple yet effective the interface is. Basically, a notebook is a linear set of cells that are either code or markdown. Code cells are executed by an associated kernel process running an R interpreter, output is fed back and attached to the associated cell.\n",
    "\n",
    "So my idea waa to convert each of the ASH dump visualization scripts into it's own notebook, separating the code into logical cells and adding markdown cells in between for explanation or motivation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup.R\n",
    "\n",
    "The original collection of R scripts included the first and critical script called `Setup.R` that read the specific ASH dump CSV files into an R data frame called `ashDF`. This data frame is the source for all plots.\n",
    "\n",
    "In addition, `Setup.R` performed the following useful transforms on `ashDF`:\n",
    "\n",
    "- `SAMPLE_TIME` has type `POSIXct` with microsecond granularity\n",
    "- column `EST_COUNT` is added, computing the estimated event count using 1000ms sampling default and measured latency (`TIME_WAITED`)\n",
    "- joined to a version of `V$EVENT_NAME` to get `EVENTNAME` and `WAITCLASS` by `EVENT_ID`\n",
    "- column `STATE` is added with values: \"CPU\", \"IO\", or \"WAIT\"\n",
    "- column 'STATE_CLASS' added with values: \"CPU\" or `WAITCLASS`\n",
    "- column `MINIT` added (`SAMPLE_TIME` truncated) for simplified aggregation over time by minute\n",
    "- all columns cast to factors except: `SAMPLE_ID`, `SAMPLE_TIME`, `MINIT`, `TIME_WAITED`, `WAIT_TIME`\n",
    "\n",
    "So all the scripts began by sourcing `Setup.R` to obtain the nice data frame `ashDF` which they then proceed to manipulate and plot using `ggplot`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook data sharing\n",
    "\n",
    "The first obstacle to executing my plan was having the various notebooks all use the same `ashDF` data frame without all executing the `Setup.R` code every time. For one thing, unnecessary details about the source data (e.g. file names) could be exposed and for another why do complex data ingest and transform every time?\n",
    "\n",
    "So I needed a good way to share the processed data frame between independently executing notebooks. They could each have their own copy, but it needs to be painless to import into the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R package `ashdat`\n",
    "\n",
    "After considering alternatives, I decided to create an R package containing the processed data frame as that would allow for easy incorporation into Notebooks. This turned out to be quite a learning experience and took several days. Basically, an R package is a collection of R code and data objects organized and documented using a set of standards set by CRAN.\n",
    "\n",
    "R Studio has built-in capabilities for developing and building R packages, and the `devtools` package from Hadley Wickham is very helpful. There are several good links on building R packages in the References cited below.\n",
    "\n",
    "So I created an R package called `ashdat` that contains a data frame called `ASHDUMP1` which is the original data frame created by the `Setup.R` script. For now the package is located in the notebook directory and is installed and loaded by all the notebooks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ashdat from current directory\n",
    "install.packages(\"./ashdat_0.1.0.tar.gz\", repos = NULL)\n",
    "library(ashdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing ashDF\n",
    "\n",
    "Once the `ashdat` package is loaded we can initialize a local `ashDF` data frame using the `ASHDUMP1` data frame stored there as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t214204 obs. of  36 variables:\n",
      " $ DBID                    : Factor w/ 1 level \"3500743502\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ INSTANCE_NUMBER         : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ SAMPLE_ID               : int  35545015 35545015 35545015 35545015 35545015 35545015 35545015 35545015 35545015 35545015 ...\n",
      " $ SAMPLE_TIME             : POSIXct, format: \"2006-10-09 12:19:24\" \"2006-10-09 12:19:24\" ...\n",
      " $ SESSION_ID              : Factor w/ 620 levels \"1522\",\"1526\",..: 22 39 75 83 92 111 120 137 163 234 ...\n",
      " $ SESSION_SERIAL.         : Factor w/ 1391 levels \"1\",\"3\",\"4\",\"5\",..: 16 494 791 222 13 616 706 66 92 11 ...\n",
      " $ USER_ID                 : Factor w/ 6 levels \"0\",\"5\",\"24\",\"55\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ SQL_ID                  : Factor w/ 1189 levels \"\",\"0486hsh0p6hcm\",..: 380 243 238 222 243 222 380 222 111 243 ...\n",
      " $ SQL_CHILD_NUMBER        : Factor w/ 39 levels \"0\",\"1\",\"2\",\"3\",..: 2 4 3 1 4 1 2 1 1 4 ...\n",
      " $ SQL_PLAN_HASH_VALUE     : Factor w/ 244 levels \"0\",\"5263284\",..: 185 185 220 55 185 55 185 55 55 185 ...\n",
      " $ SERVICE_HASH            : Factor w/ 4 levels \"0\",\"165959219\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ SESSION_TYPE            : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ SQL_OPCODE              : Factor w/ 8 levels \"0\",\"2\",\"3\",\"6\",..: 3 3 3 3 3 3 3 3 3 3 ...\n",
      " $ BLOCKING_SESSION        : Factor w/ 199 levels \"1533\",\"1557\",..: 196 196 198 195 196 196 198 196 196 196 ...\n",
      " $ BLOCKING_SESSION_SERIAL.: Factor w/ 215 levels \"0\",\"1\",\"14\",\"159\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ QC_SESSION_ID           : Factor w/ 6 levels \"0\",\"1646\",\"1778\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ QC_INSTANCE_ID          : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ XID                     : Factor w/ 17092 levels \"\",\"0100010003280D00\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ CURRENT_OBJ.            : Factor w/ 484 levels \"0\",\"1\",\"16\",\"17\",..: 405 280 283 429 280 90 405 439 94 280 ...\n",
      " $ CURRENT_FILE.           : Factor w/ 469 levels \"0\",\"1\",\"2\",\"3\",..: 132 38 33 32 350 351 336 266 355 9 ...\n",
      " $ CURRENT_BLOCK.          : Factor w/ 144659 levels \"0\",\"2\",\"3\",\"9\",..: 1901 67762 10700 75613 47446 128216 18107 58552 123111 143567 ...\n",
      " $ EVENT_ID                : Factor w/ 111 levels \"1035026728\",\"1055154682\",..: 50 50 70 50 50 50 4 50 50 50 ...\n",
      " $ SEQ.                    : Factor w/ 62915 levels \"0\",\"1\",\"2\",\"3\",..: 34093 45318 2448 47661 28577 19336 2874 55088 29983 44281 ...\n",
      " $ P1                      : Factor w/ 1655 levels \"0\",\"1\",\"2\",\"3\",..: 141 45 38 37 359 360 345 275 364 11 ...\n",
      " $ P2                      : Factor w/ 143468 levels \"0\",\"1\",\"2\",\"3\",..: 2114 67697 10948 75432 47619 127133 18333 58635 122115 142128 ...\n",
      " $ P3                      : Factor w/ 1134 levels \"0\",\"1\",\"2\",\"3\",..: 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ WAIT_TIME               : int  0 0 0 12798 0 0 0 0 0 0 ...\n",
      " $ TIME_WAITED             : int  35598 30817 2842 0 219796 15441 22999 15297 16486 34293 ...\n",
      " $ FORCE_MATCHING_SIGNATURE: Factor w/ 285 levels \"0\",\"71949771242777904\",..: 226 118 166 276 118 276 226 276 276 118 ...\n",
      " $ EST_COUNT               : int  28 32 352 1 5 65 43 65 61 29 ...\n",
      " $ STATE                   : Factor w/ 3 levels \"CPU\",\"I/O\",\"WAIT\": 2 2 3 2 2 2 3 2 2 2 ...\n",
      " $ EVENTNAME               : Factor w/ 107 levels \"ARCH wait on SENDREQ\",..: 14 14 42 14 14 14 46 14 14 14 ...\n",
      " $ WAITCLASS_ID            : Factor w/ 13 levels \"644977587\",\"1740759767\",..: 2 2 9 2 2 2 9 2 2 2 ...\n",
      " $ WAITCLASS               : Factor w/ 11 levels \"Application\",..: 11 11 2 11 11 11 2 11 11 11 ...\n",
      " $ STATE_CLASS             : Factor w/ 12 levels \"Application\",..: 12 12 2 12 12 12 2 12 12 12 ...\n",
      " $ MINIT                   : POSIXct, format: \"2006-10-09 12:19:00\" \"2006-10-09 12:19:00\" ...\n"
     ]
    }
   ],
   "source": [
    "ashDF <- ashdat::ASHDUMP1\n",
    "str(ashDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the beginning\n",
    "\n",
    "So at this point each of the original scripts should be convertible to Jupyter Notebooks in a relatively transparent way:\n",
    "\n",
    "- import entire script into a single code cell\n",
    "- subdivide that cell into logical pieces\n",
    "- insert markdown cells for explanation and motivation\n",
    "\n",
    "Mostly the scripts were simply sequences of plots, so having separate code cells for each plot seemed logical.\n",
    "\n",
    "In the coming days and weeks I will be uploading the converted scripts as Jupyter Notebooks to my [ASHviz](https://github.com/jberesni/ASHviz/tree/master/Jupyter) github repository. The scripts are pretty raw and numerous failed experiements are included, but some commentary will be there. More interesting and/or useful results may be extracted into more focused and discursive articles, probably on LinkedIn to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Anaconda] (https://www.anaconda.com/)\n",
    "2. [R Packages](http://r-pkgs.had.co.nz/) by Hadley Wickham\n",
    "3. [Writing an R package from scratch](https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/) blog by Hilary Parker\n",
    "4.[Making Your First R Package](http://tinyheero.github.io/jekyll/update/2015/07/26/making-your-first-R-package.html) blog by Fong Chun Chan\n",
    "5. [R package primer] (https://kbroman.org/pkg_primer/) Karl Broman\n",
    "\n",
    "Basically anyone getting started with using R for data analysis and plotting should become familiar with the incredibly useful software and documentation put out by Hadley Wickham."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
